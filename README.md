# The New Canny Valley

There is a continuum: Humans are taking Turing tests to prove to robots that we are human, but what we perceive as real is mediated by “robots.” By virtualizing our experiences, we’ve begun to use machine learning to mediate our access to knowledge and our senses. Virtual learning is a quick and iterable learning loop, but when we involve the real world, things slow down to a real-life pace. Now that machine learning models can be embedded in microcontrollers, and mobile devices can now act as senses and actuators. This advance allows machine learning techniques to enable increased accessibility and inclusivity. In this talk, we’ll walk through the details with examples from Minecraft to DIY robot projects.

